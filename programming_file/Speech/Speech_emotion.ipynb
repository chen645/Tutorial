{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (0.8.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from librosa) (1.19.5)\n",
      "Requirement already satisfied: numba>=0.43.0 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from librosa) (0.52.0)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from librosa) (0.24.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: setuptools in /home/jack/.local/lib/python3.8/site-packages (from numba>=0.43.0->librosa) (52.0.0)\n",
      "Requirement already satisfied: llvmlite<0.36,>=0.35.0 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from numba>=0.43.0->librosa) (0.35.0)\n",
      "Requirement already satisfied: requests in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from pooch>=1.0->librosa) (2.25.1)\n",
      "Requirement already satisfied: packaging in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from pooch>=1.0->librosa) (20.4)\n",
      "Requirement already satisfied: appdirs in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: six>=1.3 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from soundfile>=0.9.0->librosa) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from packaging->pooch>=1.0->librosa) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa) (2020.6.20)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/jack/anaconda3/envs/exp38/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa) (4.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/jack/anaconda3/envs/exp38/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.57.0-py2.py3-none-any.whl (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 139 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.57.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/jack/anaconda3/envs/exp38/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from librosa import display\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(file):\n",
    "    #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
    "    X, sample_rate = librosa.load(file, res_type='kaiser_fast')\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
    "    # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
    "    # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
    "  # If the file is not valid, skip it\n",
    "    \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {'angry':0, 'disgust':1, 'fearful':2,'happy':3,'neutral':4,'sad':5,'surprised':6}\n",
    "def data_extract(data):\n",
    "    data_path = data+'/*/*.wav' \n",
    "    img_paths = glob(data_path)\n",
    "    data_count = len(glob(data_path))\n",
    "    print(data_count)\n",
    "\n",
    "    X = np.zeros((data_count, 40))\n",
    "    y = np.zeros((data_count, ))\n",
    "    for i, path in tqdm(sorted(enumerate(img_paths))):\n",
    "\n",
    "        X[i] = extract_mfcc(path)\n",
    "\n",
    "        cls = path.split('/')[-2]\n",
    "\n",
    "        y[i] = class_map[cls]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train data Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1963 [00:00<01:38, 19.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1963/1963 [02:14<00:00, 14.65it/s]\n"
     ]
    }
   ],
   "source": [
    "X,y =data_extract('train') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1963,)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import keras\n",
    "X_name = 'X_train.joblib'\n",
    "y_name = 'y_train.joblib'\n",
    "\n",
    "y_onehot = keras.utils.to_categorical(y, num_classes=7)\n",
    "print(y.shape)\n",
    "savedX = joblib.dump(X,X_name)\n",
    "savedy = joblib.dump(y_onehot, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1963, 40, 1) (1963, 7)\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_168 (Conv1D)          (None, 40, 16)            96        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_184 (LeakyReLU)  (None, 40, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_167 (Dropout)        (None, 40, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 20, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 20, 32)            2592      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_185 (LeakyReLU)  (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_168 (Dropout)        (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 10, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 10, 64)            10304     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_186 (LeakyReLU)  (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_169 (Dropout)        (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 5, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 5, 128)            41088     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_187 (LeakyReLU)  (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_170 (Dropout)        (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 2, 256)            164096    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_188 (LeakyReLU)  (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "dropout_171 (Dropout)        (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_189 (LeakyReLU)  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 7)                 903       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 251,975\n",
      "Trainable params: 251,975\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train = joblib.load('X_train.joblib')\n",
    "y_train = joblib.load('y_train.joblib')\n",
    "\n",
    "\n",
    "\n",
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "print(x_traincnn.shape,y_train.shape)\n",
    "print(y_train[0])\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Flatten, Dropout, Activation\n",
    "from tensorflow.python.framework import tensor_util\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D,LSTM,LeakyReLU,Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(16, 5,padding='same',\n",
    "                 input_shape=(40,1)))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Conv1D(32, 5,padding='same'))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Conv1D(64, 5,padding='same',))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Conv1D(128,5,padding='same',))\n",
    "model.add(LeakyReLU())\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Conv1D(256, 5,padding='same',))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1963, 40, 1) (1963, 7)\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must have the same first dimension, got logits shape [128,7] and labels shape [896]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-149-478907783404>:5) ]] [Op:__inference_train_function_1080262]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-478907783404>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_traincnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcnnhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_traincnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/exp38/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 _r=1):\n\u001b[1;32m   1133\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/exp38/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/exp38/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/exp38/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2991\u001b[0m       (graph_function,\n\u001b[1;32m   2992\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2993\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2994\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/exp38/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1937\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1939\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1940\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/exp38/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    562\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    565\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/exp38/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  logits and labels must have the same first dimension, got logits shape [128,7] and labels shape [896]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-149-478907783404>:5) ]] [Op:__inference_train_function_1080262]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print(x_traincnn.shape, y_train.shape)\n",
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=128, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/489 [00:00<00:23, 20.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [00:40<00:00, 12.10it/s]\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('ASR1.h5')\n",
    "import joblib\n",
    "import keras\n",
    "\n",
    "X_name = 'X_test.joblib'\n",
    "y_name = 'y_test.joblib'\n",
    "'''\n",
    "x_testcnn,y_test =data_extract('test') \n",
    "y_onehot = keras.utils.to_categorical(y_test, num_classes=7)\n",
    "joblib.dump(x_testcnn,X_name)\n",
    "joblib.dump(y_onehot, y_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testcnn = joblib.load('X_test.joblib')\n",
    "y_test = joblib.load('y_test.joblib')\n",
    "prediction_name = 'speech_prediction'\n",
    "x_testcnn = np.expand_dims(x_testcnn, axis=2)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "y_pred = np.argmax(model.predict(x_testcnn), axis=-1)\n",
    "y_test = np.argmax(y_test, axis=-1)\n",
    "savedprediction = joblib.dump(y_pred, prediction_name)\n",
    "target_names = ['angry', 'disgust', 'fearful','happy','neautral','sad','surprised']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
